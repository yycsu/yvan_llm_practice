{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包和变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？\n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。\n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "2  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "1  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "2  -0.02707982249557972,-0.009818901307880878,-0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 引入PyPDFDirectoryLoader，可以从文件夹中一次性加载所有pdf文件\n",
    "# 然后使用RecursiveCharacterTextSplitter对解析出来的文档进行切分，主要根据分隔符，chunk_size以及overlap等\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers.bm25 import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "DOCS_DIR = '/root/autodl-tmp/dataset/rag/A_document'\n",
    "EMB_MODEL = '/root/autodl-tmp/models/bge-large-zh-v1_5'\n",
    "RERANK_MODEL = \"/root/autodl-tmp/models/bge-reranker-large\"\n",
    "PERSIST_DIR = '/root/autodl-tmp/vectorDatabase/faiss'\n",
    "QUERY_DIR = '/root/autodl-tmp/dataset/rag/A_question.csv'\n",
    "SUB_DIR = '/root/autodl-tmp/dataset/rag/submit.csv'\n",
    "query = pd.read_csv(QUERY_DIR)\n",
    "sub = pd.read_csv(\"/root/autodl-tmp/dataset/rag/submit_example.csv\")\n",
    "display(query.head(3))\n",
    "display(sub.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF文档解析和切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 560, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 170, in _handle_event\n",
      "    event_f()\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 649, in _flush\n",
      "    self.session.send(\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 852, in send\n",
      "    elif stream:\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 721, in serialize\n",
      "    pass\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    allow_nan=False,\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n",
      "ERROR:tornado.general:Uncaught exception in zmqstream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 610, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 639, in _hanException in callback BaseAsyncIOLoop._handle_events(32, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(32, 1)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 202, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 610, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 639, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 560, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 170, in _handle_event\n",
      "    event_f()\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 649, in _flush\n",
      "    self.session.send(\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 852, in send\n",
      "    elif stream:\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 721, in serialize\n",
      "    pass\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    allow_nan=False,\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n",
      "dle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 560, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 170, in _handle_event\n",
      "    event_f()\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/ipykernel/iostream.py\", line 649, in _flush\n",
      "    self.session.send(\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 852, in send\n",
      "    elif stream:\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 721, in serialize\n",
      "    pass\n",
      "  File \"/root/miniconda3/envs/dl/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    allow_nan=False,\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 713444-713448: surrogates not allowed\n"
     ]
    }
   ],
   "source": [
    "# 进行数据加载\n",
    "loader = PyPDFDirectoryLoader(DOCS_DIR)\n",
    "\n",
    "docs = loader.load_and_split(\n",
    "    RecursiveCharacterTextSplitter(        \n",
    "        chunk_size=200,             \n",
    "        chunk_overlap=0,\n",
    "        separators = [\"。\", \"！\", \"？\"],\n",
    "        keep_separator='end',\n",
    "    ),\n",
    ")\n",
    "# 打印文档数量\n",
    "print(len(docs))\n",
    "# print(docs[0].page_content)\n",
    "\n",
    "# # 打印所有第一页的数据出来看下，切分效果如何\n",
    "# for i, item in enumerate(docs):\n",
    "#     print(f\"the {i} doc's content i: {item.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本块向量化（比赛限定使用bge-large-zh-v1.5模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 154/154 [00:32<00:00,  4.71it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
    "vectordb = FAISS.from_documents(   \n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "vectordb.save_local(PERSIST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合检索器\n",
    "\n",
    "#### bm25 \n",
    "- k1 较高的 k1 值意味着词频对评分的影响更大。\n",
    "- b  当 b=1 时，文档长度的影响最大；当b = 0 时，文档长度不影响评分。\n",
    "- langchain 默认切分英文split()，中文需要jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "dense_retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    docs, \n",
    "    k=5, \n",
    "    bm25_params={\"k1\": 1.5, \"b\": 0.75}, \n",
    "    preprocess_func=jieba.lcut\n",
    ")\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本召回和重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "def rerank(questions, retriever, top_n=5, cut_len=384):\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    "    )\n",
    "    rerank_answers = []\n",
    "    for question in tqdm(questions):\n",
    "        relevant_docs = compression_retriever.invoke(question)\n",
    "        answer=''\n",
    "        for rd in relevant_docs:\n",
    "            answer += rd.page_content\n",
    "        rerank_answers.append(answer[:cut_len])\n",
    "    return rerank_answers\n",
    "\n",
    "questions = list(query['question'].values)\n",
    "rerank_answers = rerank(questions, ensemble_retriever)\n",
    "print(rerank_answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb(answers, emb_batch_size = 4):\n",
    "    model = SentenceTransformer(EMB_MODEL, trust_remote_code=True).half()\n",
    "    all_sentence_embeddings = []\n",
    "    for i in tqdm(range(0, len(answers), emb_batch_size), desc=\"embedding sentences\"):\n",
    "        batch_sentences = answers[i:i+emb_batch_size]\n",
    "        sentence_embeddings = model.encode(batch_sentences, normalize_embeddings=True)\n",
    "        all_sentence_embeddings.append(sentence_embeddings)\n",
    "    all_sentence_embeddings = np.concatenate(all_sentence_embeddings, axis=0)\n",
    "    print('emb_model max_seq_length: ', model.max_seq_length)\n",
    "    print('emb_model embeddings_shape: ', all_sentence_embeddings.shape[-1])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return all_sentence_embeddings\n",
    "\n",
    "all_sentence_embeddings = emb(rerank_answers)\n",
    "sub['answer'] = rerank_answers\n",
    "sub['embedding']= [','.join([str(a) for a in all_sentence_embeddings[i]]) for i in range(len(all_sentence_embeddings))]\n",
    "sub.to_csv(SUB_DIR, index=None)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后续可能提分点\n",
    "- 引入LLM\n",
    "   * LLM 递归判断/抽取\n",
    "   * rag-fusion 查询改写\n",
    "   * 构建知识图谱\n",
    "\n",
    "\n",
    "\n",
    "### 注意：\n",
    "- 在分块、重排等过程中可以使用公开库和模型，但禁止使用LLM直接生成最终答案。\n",
    "- 禁止使用LLM继续调整精排得到的文本块，如压缩文本块长度；\n",
    "- 禁止使用LLM直接从文档获取问题答案。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
