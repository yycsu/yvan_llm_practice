{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包和变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_fyde</th>\n",
       "      <th>sub_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>根据2022年年度报告，中国联通在向数字科技领军企业转变的过程中，实现了以下维度的转型升级：...</td>\n",
       "      <td>[根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>2022年中国联通产业互联网收入同比增长速度为13.8%。</td>\n",
       "      <td>[告诉我2022年联通产业互联网收入的同比增长速度。, 2022年联通产业互联网收入是多少？]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是：\\n\\n1. 成为数字创新服务领导者\\n2. 推...</td>\n",
       "      <td>[根据2022年度报告，中国联通的企业定位是什么？, 中国联通的企业定位包含哪些具体内容？]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "\n",
       "                                       question_fyde  \\\n",
       "0  根据2022年年度报告，中国联通在向数字科技领军企业转变的过程中，实现了以下维度的转型升级：...   \n",
       "1                      2022年中国联通产业互联网收入同比增长速度为13.8%。   \n",
       "2  根据2022年度报告，中国联通的企业定位是：\\n\\n1. 成为数字创新服务领导者\\n2. 推...   \n",
       "\n",
       "                                       sub_questions  \n",
       "0  [根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？...  \n",
       "1    [告诉我2022年联通产业互联网收入的同比增长速度。, 2022年联通产业互联网收入是多少？]  \n",
       "2     [根据2022年度报告，中国联通的企业定位是什么？, 中国联通的企业定位包含哪些具体内容？]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...</td>\n",
       "      <td>-0.02707982249557972,-0.009818901307880878,-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "1  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "2  我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "1  -0.02707982249557972,-0.009818901307880878,-0....  \n",
       "2  -0.02707982249557972,-0.009818901307880878,-0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 引入PyPDFDirectoryLoader，可以从文件夹中一次性加载所有pdf文件\n",
    "# 然后使用RecursiveCharacterTextSplitter对解析出来的文档进行切分，主要根据分隔符，chunk_size以及overlap等\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers.bm25 import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "DOCS_DIR = '/root/autodl-tmp/dataset/rag/A_document'\n",
    "# DOCS_DIR = '/root/autodl-tmp/dataset/rag/A_small'\n",
    "EMB_MODEL = '/root/autodl-tmp/models/bge-large-zh-v1_5'\n",
    "RERANK_MODEL = \"/root/autodl-tmp/models/bge-reranker-large\"\n",
    "PERSIST_DIR = '/root/autodl-tmp/vectorDatabase/faiss_llmsherpa'\n",
    "QUERY_DIR = '/root/autodl-tmp/dataset/rag/A_question.csv'\n",
    "SUB_DIR = '/root/autodl-tmp/dataset/rag/submit.csv'\n",
    "# query = pd.read_csv(QUERY_DIR)\n",
    "\n",
    "path = \"/root/autodl-tmp/dataset/rag/query.pkl\"\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    query = pickle.load(f)\n",
    "\n",
    "\n",
    "sub = pd.read_csv(\"/root/autodl-tmp/dataset/rag/submit_example.csv\")\n",
    "display(query.head(3))\n",
    "display(sub.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对query使用子问题拆分方法进行扩充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "# 获取上一级目录\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# 将上一级目录添加到 sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import List\n",
    "from glm4.glm4LLM_VLLM import ChatGLM4_LLM\n",
    "\n",
    "# # LLM Configuration\n",
    "# def get_subquery_llm(model_name: str = \"gpt-4o\", temperature: float = 0, max_tokens: int = 4000) -> ChatOpenAI:\n",
    "#     return ChatOpenAI(temperature=temperature, model_name=model_name, max_tokens=max_tokens)\n",
    "\n",
    "# Sub-query Decomposition Prompt Template\n",
    "def create_subquery_decomposition_template() -> PromptTemplate:\n",
    "    template = \"\"\"你是一名 AI 助手，任务是将复杂的查询分解为更简单的子查询，以便 RAG 系统处理。\n",
    "给定原始查询，将其分解为 2 个更简单的子查询，这些子查询结合在一起可以为原始查询提供全面的回答。\n",
    "请注意，返回结果将两个子查询用‘#’字符拼接起来，不需要输出任何额外的字符\n",
    "\n",
    "原始查询：{original_query}\n",
    "示例0:\n",
    "原始查询：中国联通推出的专属反诈号码是多少？\n",
    "\n",
    "中国联通推出的专属反诈号码是多少？\n",
    "\n",
    "示例1:\n",
    "原始查询：2020年上半年，联通固网宽带的收入和用户数增长了多少？\n",
    "\n",
    "2020年上半年，联通固网宽带的收入增长了多少？#2020年上半年，联通固网宽带的用户数增长了多少？\n",
    "\n",
    "示例2:\n",
    "原始查询：统计数据显示，2022年我国算力规模增长、数字经济和GDP名义分别增长多少？\n",
    "\n",
    "统计数据显示，2022年我国算力规模增长多少？#统计数据显示，2022年我国数字经济和GDP名义增常多少？\n",
    "\n",
    "示例3:\n",
    "原始查询：根据IDC数据，2022年全球数据总产量和过去五年平均增速分别是多少？\n",
    "\n",
    "根据IDC数据，2022年全球数据总产量和是多少？#2022年过去五年的平均增速分别是多少？\n",
    "\"\"\"\n",
    "    return PromptTemplate(input_variables=[\"original_query\"], template=template)\n",
    "\n",
    "# Build Sub-query Decomposition Chain\n",
    "def build_subquery_decomposer_chain(llm: ChatOpenAI) -> LLMChain:\n",
    "    prompt_template = create_subquery_decomposition_template()\n",
    "    return prompt_template | llm\n",
    "\n",
    "# Function to Decompose Query into Sub-queries\n",
    "def decompose_query(original_query: str, subquery_chain: LLMChain) -> List[str]:\n",
    "    response = subquery_chain.invoke(original_query)\n",
    "    # Parse the sub-queries by splitting lines and removing unwanted text\n",
    "    sub_queries = [q.strip() for q in response.split('#') if q.strip() and not q.strip().startswith('Sub-queries:')]\n",
    "    print(sub_queries)\n",
    "    return sub_queries\n",
    "\n",
    "def get_sub_queries(query):\n",
    "    llm = ChatGLM4_LLM(api_base_url=\"http://localhost:8000/v1\")\n",
    "    subquery_chain = build_subquery_decomposer_chain(llm)\n",
    "    # original_query = \"根据IDC数据，2022年全球数据总产量和过去五年平均增速分别是多少？\"\n",
    "    sub_queries = decompose_query(query, subquery_chain)\n",
    "    return sub_queries\n",
    "\n",
    "# print(\"\\nSub-queries:\")\n",
    "# for i, sub_query in enumerate(sub_queries, 1):\n",
    "#     print(f\"{i}. {sub_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？', '2022年中国联通在向数字科技领军企业转变的过程中，具体在哪些方面实现了转型升级']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['告诉我2022年联通产业互联网收入的同比增长速度？', '2022年联通产业互联网收入是多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['根据2022年度报告，中国联通的企业定位是什么？', '中国联通的企业定位包含哪些具体内容？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年联通在大联接业务上取得了什么成果？', '2022年联通在大数据业务上取得了什么成果？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年上半年，联通5G网络覆盖情况如何？', '2022年上半年，联通精品网络建设总体成果有哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年半年度报告指出联通在5G网络建设方面取得的进展是什么？', '2022年半年度报告指出联通在物联网应用拓展方面取得的进展是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年第一季度中国联通应收账款变动主要原因是什么？', '2022年第三季度中国联通应收账款变动主要原因是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年第一季度，中国联通财务指标中存货变动的主要原因是什么？', '2022年第一季度，中国联通财务指标中存货变动的主要原因可能包括以下几点']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['查询2022年年度报告或季度报告中联通在北京冬奥会和冬残奥会上运用了哪些技术保障通信服务', '2022年年度报告或季度报告中联通在北京冬奥会和冬残奥会上技术保障通信服务的应用效果如何']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年第一季度期末，中国联合网络通信集团有限公司的自有持股比例是多少？', '中国联合网络通信集团有限公司（中国联通）2022年第一季度期末的具体自...']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['介绍2022年联通董事会审计委员会的董事姓名', '2022年联通董事会审计委员会的董事职位']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通的股票代码是多少？', '中国联通的股票代码在上海和香港分别是多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通股票在上海证券交易所上市', '中国联通股票代码是多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['根据年度报告摘要，中国联通2020年在国际网络建设方面取得了哪些成果？', '解读中国联通2020年国际网络建设成果']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['帮我查询2020年中国联通产业互联网业务收入情况。', '2020年中国联通产业互联网业务收入情况查询步骤']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['抗击新冠疫情工作介绍', '助力复工复产工作介绍']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2020年上半年，联通固网宽带收入增长了多少？', '2020年上半年，联通固网宽带用户数增长了多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2020年上半年，联通与哪些企业通过合资公司保持了战略合作？', '2020年上半年，联通与哪些企业通过联合实验室保持了战略合作？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2020年第三季度报告指出联通如何应对疫情防控常态化造成的宽带组网需求提升？', '2020年第三季度报告指出联通如何应对疫情防控常态化造成的提速需求提升？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2019年底联通宽带端口总数为多少？', '2020年底联通宽带端口总数为多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['根据联通年度报告，2019年手机用户月户均数据流量是多少？', '根据联通年度报告，2020年手机用户月户均数据流量是多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2019年中国联通移动业务发展策略调整内容', '2019年中国联通移动业务网络升级情况']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2019年中国联通智慧家庭产品', '智慧家庭产品具体内容']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['《关于公司限制性股票激励计划首期授予方案实施预留授予的议案》审议通过的具体日期是什么？', '查阅中国联通最...']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['我国5G政策特点', '我国5G政策发展时间表和路线图']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['5G技术推动了哪些新兴业态展现发展潜力？', '5G技术推动的工业互联网发展潜力如何？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2023年上半年，我国厂商在全球5G手机出货量中具体出货量是多少？', '2023年上半年，我国厂商在全球5G手机出货量中的市场份额达到了60%...']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['5G-A预计包含哪些版本？', '5G-A Phase 1包含哪些内容？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2023年我国持续完善重点网络安全制度要求的具体措施是什么？', '2023年我国在网络安全制度要求方面采取了哪些措施？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['根据IDC数据，2022年全球数据总产量是多少？', '2022年全球数据过去五年平均增速是？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['统计数据显示，2022年我国算力规模增长多少？', '统计数据显示，2022年我国数字经济和GDP名义增长多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['我国区块链发展面临的主要挑战有哪些？', '中国区块链发展面临的主要挑战：法律法规不完善？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['截至2023年12月，中国区块链企业数量', '截至2023年12月，美国区块链企业数量']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['互联网平台责任规范体现规则', '平台发展法治环境优化体现']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['联通资产运营公司有什么座右铭？', '吴永的座右铭是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2023年中国科协“创新达人”河南省评选活动', '南作获得的具体荣耀']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['云南省临沧市临翔区圈内乡斗阁村森林火灾事件中中国联通省分公司行动措施', '中国联通在森林火灾事件中的行动详情']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['广东联通志愿服务队在21个地市开展“青春暖夕阳”专场活动的场次是多少？', '参与该活动的志愿者人次达到多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['“云尚蓟州”平台提供的智能导览服务有哪些？', '“云尚蓟州”平台提供的其他智能化旅游服务有哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['渔政核查核录系统自正式上线以来识别率精度达到了多少？', '渔政核查核录系统自正式上线以来累计完成了多少次AI预警？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['被大家称为“托举哥”的英雄是谁？', '他是在哪个火车站进行了托举行为？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2024中国联通合作伙伴大会的主题是什么？', '“人工智能赋能智慧车联网论坛”的主题是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2023年义乌市出口额是多少？', '2023年义乌市进口额是多少？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通智能城市研究院依托自研的璇玑“5G+北斗”时空基座是什么？', '基于元景大模型构建的中国联通时空...']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通推出的“畅游欧洲，激情巴黎”出境漫游随心选活动提供了哪些流量套餐？', '“畅游欧洲，激情巴黎”出境漫游随心选活动为用户提供了哪四种流量套餐选择？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['“游新疆”小程序是谁打造的？', '“游新疆”小程序是由谁打造的？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['三苏文化大数据库的打造目的主要是什么？', '三苏文化大数据库的打造目的是为了什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通在2024年世界智能产业博览会上的主题是什么主题？', '2024年世界智能产业博览会的主题是“Digitization Drives the Future”']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通的卡通形象“通通”是什么？', '“通通”寓意着什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['湖南联通在岳阳华容团洲垸决堤后采取的紧急抢修行动有哪些？', '湖南联通在岳阳华容团洲垸决堤后采取了哪些恢复通信的具体行动']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通经济社会智能孪生系统建设的三大核心特色是什么？', '中国联通经济社会智能孪生系统建设的数据驱动特色是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['IDC MarketScape报告评估厂商的标准是什么？', 'IDC MarketScape报告评估厂商的标准通常包括以下几个方面：1. 市场份额等']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通旗下的哪两个企业入选国资委“创建世界一流示范企业和专精特新示范企业”名单？', '中国联通旗下的两个企业分别是哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通人工智能创新发展论坛上，客户分享了元景大模型在哪些行业应用案例？', '元景大模型在中国联通人工智能创新发展论坛上的分享中，涉及哪些具体行业的应用案例？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通举办人工智能创新发展论坛', '论坛具体日期']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['紫金山实验室使用仿真平台进行有效性测试的原因是什么？', '仿真平台测试的成本效益如何？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['告诉我紫金山实验室位于哪个城市？', '紫金山实验室位于哪个城市']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通董事长刘烈宏在2022年中国联通合作伙伴大会上提到的联通五大主责主业是什么？', '联通五大主责主业具体内容是什么']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年世界宽带论坛上中国联通获奖情况', '中国联通在2022年世界宽带论坛上获得的奖项是什么']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['国企改革三年行动的“三个明显成效”包括什么？', '国企改革三年行动的“三个明显成效”具体是权利责任划分更加清晰']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通董事长陈忠岳在2024中国联通合作伙伴大会上提出的倡议有哪些？', '陈忠岳在2024中国联通合作伙伴大会上提出的倡议具体内容是什么']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['联通在内蒙古智算中心上线的算力调度平台名称是什么？', '什么是内蒙古智算中心上线的算力调度平台？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['新一轮国企改革深化提升行动的重点是什么？', '新一轮国企改革深化提升行动的重点包括哪些方面？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通荣获2023年“边缘计算技术创新先锋案例”的项目有哪些？', '这些项目分别是哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通“银龄跨越数字鸿沟专项行动”在哪些服务窗口提供专属服务？', '65岁以上客户专属服务内容']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['查一下2024年中国品牌日的主题', '查一下2024年中国品牌日的举办日期']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['联通“格物”平台在南京南部新城项目建设过程中解决了哪些难题？', '南京南部新城项目建设过程中遇到的难题']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['国资委党委党史学习教育总结会议上指出坚决反对的主义是哪些？', '个人主义、本位主义']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['国务院国资委党委举办党纪学习教育读书班的目的？', '加强党风廉政建设和反腐败斗争，提高党员干部...']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通在第五届“绽放杯”5G应用征集大赛中获得了哪些奖项？', '中国联通在第五届“绽放杯”5G应用征集大赛中获得的每个奖项名称']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通通过5G技术帮助金珠沙梨产业升级的步骤有哪些？', '中国联通5G技术在金珠沙梨产业升级中的具体应用案例有哪些']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['联通云PaaS平台提供的自研操作系统名为什么？', '联通麒麟操作系统']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2024年7月19日，中国联通人工智能创新中心推出了元景2.0版本是什么？', '元景2.0版本是哪个']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2024年7月19日元景2.0发布的三大基础模型分别是哪些？', '元景2.0包括的三大基础模型具体内容是什么']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通的冬奥网络规划遵循的核心理念是什么？', '中国联通冬奥网络规划中的安全可靠内容是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['5G技术在北京冬奥会中的应用特点包括哪些？', '5G技术在北京冬奥会应用的高速率传输特点是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['智慧医疗在5G环境下能实现哪些功能？', '远程会诊能利用5G实现哪些功能？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通智算联盟的愿景是什么？', '中国联通智算联盟的愿景包含哪些要素？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['联通云联合晋云科技打造的“能源智算云”主要用于什么需求？', '“能源智算云”是基于以下需求打造的：']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通提出的L4级蓝图是什么？', 'L4级蓝图的应用背景是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通的主营业务包括哪两类？', '通信服务类和信息服务类分别包含哪些业务']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通旗下入选国资委“创建世界一流专精特新示范企业”的是哪家公司？', '该公司的名称是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['截至2024年4月，联通数字乡村平台覆盖了多少个行政村？', '截至2024年4月，联通数字乡村平台服务了多少户村户？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通推出的专属反诈号码是什么？', '该号码对应的官方描述是什么']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通党员干部主题教育总要求是什么？', '习近平新时代中国特色社会思想中关于主题教育的总要求是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['北京联通重要通信保障团队的三个“零”目标是什么？', '刘申申要实现哪三个“零”目标？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通在政务云平台建设方面有哪些成果？', '中国联通在政务大数据平台建设方面的其他成果有哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通5G网络建设成果有哪些？', '中国联通数字经济平台建设其他成果有哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通在浙江数字机关建设方面的5G技术应用有哪些成果？', '中国联通在浙江数字机关建设方面的其他成果有哪些？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通自主研发的平台名称是什么？', '这个平台被国家博物馆的收藏情况如何？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['中国联通建立了什么平台？', '实现涉诈号码精准发现、快速处置的平台是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['河南联通针对3G网络升级进度不一的问题采取措施', '采取的措施包括全面评估']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2022年泰安肥城联通为听障人士设计的第一款通信产品是什么？', '2022年泰安肥城联通为视障人士设计的第一款通信产品是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['上海联通北区分公司党员发展培训机制是什么？', '上海联通北区分公司培养业务骨干成为党员的具体机制是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['上海联通北区分公司“共产党员工程”具体目标是什么？', '“共产党员工程”在提升服务品质方面的具体目标是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2018年中国联通下调国际漫游资费的具体方面是哪些？', '2018年中国联通下调国际漫游资费后，通话费用如何变化？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2017年5月，中国联通第一次降低国际漫游资费主要特征是什么？', '2017年5月，中国联通第二次降低国际漫游资费主要特征是什么？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['2017年，围绕服务“一带一路”沿线国家产业互联网发展，中国联通面向哪些重点行业客户？', '2017年中国联通如何服务“一带一路”沿线国家产业互联网发展']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['三强化具体内容是什么？', '三坚持是中国联通在开展调查研究工作时提出的工作要求？']\n",
      "正在从本地加载模型...\n",
      "完成本地模型的加载\n",
      "['截至2017年12月26日，北京市2022年冬奥会和冬残奥会官方合作伙伴共有几家？', '截至2017年12月26日，北京市2022年冬奥会和冬残奥会官方合作伙伴分别是哪几家？']\n"
     ]
    }
   ],
   "source": [
    "query['sub_questions'] = query.apply(get_sub_queries, axis=1)\n",
    "\n",
    "path = \"/root/autodl-tmp/dataset/rag/query.pkl\"\n",
    "\n",
    "with open(path, \"wb\") as f:\n",
    "    pickle.dump(query, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 100}\n"
     ]
    }
   ],
   "source": [
    "# 使用 Pandas 的 apply 和 value_counts 方法\n",
    "length_counts = query['sub_questions'].apply(len).value_counts().to_dict()\n",
    "\n",
    "print(length_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？',\n",
       " '2022年中国联通在向数字科技领军企业转变的过程中，具体在哪些方面实现了转型升级']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(query[\"sub_questions\"].values)[0]\n",
    "# list(query[\"question\"].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = list(query['question_fyde'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对query使用hyde方法进行扩充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# # from yvan_llm_practice.glm4.glm4LLM_VLLM import ChatGLM4_LLM\n",
    "# # import os\n",
    "# # import sys\n",
    "# # # 获取当前工作目录\n",
    "# # current_dir = os.getcwd()\n",
    "# # # 获取上一级目录\n",
    "# # parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# # # 将上一级目录添加到 sys.path\n",
    "# # sys.path.insert(0, parent_dir)\n",
    "\n",
    "# from glm4.glm4LLM_VLLM import ChatGLM4_LLM\n",
    "\n",
    "# # system = \"\"\"You are an expert about a set of software for building LLM-powered applications called LangChain, LangGraph, LangServe, and LangSmith.\n",
    "\n",
    "# # LangChain is a Python framework that provides a large set of integrations that can easily be composed to build LLM applications.\n",
    "# # LangGraph is a Python package built on top of LangChain that makes it easy to build stateful, multi-actor LLM applications.\n",
    "# # LangServe is a Python package built on top of LangChain that makes it easy to deploy a LangChain application as a REST API.\n",
    "# # LangSmith is a platform that makes it easy to trace and test LLM applications.\n",
    "\n",
    "# # Answer the user question as best you can. Answer as though you were writing a tutorial that addressed the user question.\"\"\"\n",
    "\n",
    "# system = \"\"\"你是一名中国联通的专家，精通公司内部的各项业务和技术。你具备以下背景知识：\n",
    "\n",
    "# 技术前沿：深入了解5G、物联网、大数据和人工智能在通信行业的应用和发展方向。\n",
    "# 数字化转型：帮助企业和政府客户实现数字化转型，通过智能化解决方案提升效率和竞争力。\n",
    "# 全球视野：熟悉中国联通在国际市场的布局和合作策略，推动全球通信网络的互联互通。\n",
    "# 创新驱动：关注技术创新，支持公司在云计算、区块链等新兴领域的探索和应用。\n",
    "# 用户导向：以用户为中心，致力于提升服务质量和用户体验，满足多样化的客户需求。\n",
    "# 社会责任：积极参与公益事业，推动教育和环保项目，履行企业社会责任。\n",
    "\n",
    "# 尽可能好地回答用户问题。回答时要像在写一个教程，以解决用户的问题。\n",
    "# 一定要注意，直接回答问题，不需要多余的任何冗余\"\"\"\n",
    "\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "# # llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "# llm = ChatGLM4_LLM(api_base_url=\"http://localhost:8000/v1\")\n",
    "# qa_no_context = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"2019年底和2020年底，联通宽带端口总数分别为多少？\"\n",
    "\n",
    "# answer = qa_no_context.invoke(\n",
    "#     {\n",
    "#         \"question\": question\n",
    "#     }\n",
    "# )\n",
    "# print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_process(question):\n",
    "#     answer = qa_no_context.invoke(\n",
    "#         {\n",
    "#             \"question\": question\n",
    "#         }\n",
    "#     )\n",
    "#     return answer\n",
    "\n",
    "# query['question_fyde'] = query.apply(data_process, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "\n",
    "# path = \"/root/autodl-tmp/dataset/rag/query.pkl\"\n",
    "# with open(path, \"wb\") as f:\n",
    "#     pickle.dump(result, f)\n",
    "\n",
    "# result[\"question_fyde\"] = result[\"question_fyde\"].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "# with open(path, \"rb\") as f:\n",
    "#     result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF文档解析和切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 进行数据加载\n",
    "# # loader = PyPDFDirectoryLoader(DOCS_DIR)\n",
    "\n",
    "# # 使用 PyPDFDirectoryLoader 加载所有 PDF 文件\n",
    "# pdf_loader = PyPDFDirectoryLoader(DOCS_DIR)\n",
    "# documents = pdf_loader.load()\n",
    "\n",
    "# # 使用 LLMSherpaFileLoader 加载文档\n",
    "# sherpa_loader = LLMSherpaFileLoader(\n",
    "#     new_indent_parser=True,\n",
    "#     apply_ocr=False,\n",
    "#     strategy=\"text\",\n",
    "#     # llmsherpa_api_url=\"http://127.0.0.1:5001/api/parseDocument?renderFormat=all&useNewIndentParser=true&applyOcr=yes\"\n",
    "#     llmsherpa_api_url=\"http://0.0.0.0:5001/api/parseDocument?renderFormat=all\",\n",
    "# )\n",
    "\n",
    "# loaded_documents = [sherpa_loader.load(doc) for doc in documents]\n",
    "\n",
    "# from langchain_community.document_loaders.llmsherpa import LLMSherpaFileLoader\n",
    "\n",
    "# loader = LLMSherpaFileLoader(\n",
    "#     file_path=\"/root/autodl-tmp/dataset/rag/A_small/AF01.pdf\",\n",
    "#     new_indent_parser=True,\n",
    "#     apply_ocr=False,\n",
    "#     strategy=\"text\",\n",
    "#     llmsherpa_api_url=\"http://0.0.0.0:5001/api/parseDocument?renderFormat=all\",\n",
    "# )\n",
    "\n",
    "# docs = loader.load_and_split(\n",
    "#     RecursiveCharacterTextSplitter(        \n",
    "#         chunk_size=200,             \n",
    "#         chunk_overlap=0,\n",
    "#         separators = [\"。\", \"！\", \"？\"],\n",
    "#         keep_separator='end',\n",
    "#     ),\n",
    "# )\n",
    "# # 打印文档数量\n",
    "# print(len(docs))\n",
    "# # print(docs[0].page_content)\n",
    "\n",
    "# # 打印所有第一页的数据出来看下，切分效果如何\n",
    "# for i, item in enumerate(docs):\n",
    "#     print(f\"the {i} doc's content i: {item.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗之前的chunk数量：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13986"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.llmsherpa import LLMSherpaFileLoader\n",
    "\n",
    "\n",
    "# 指定 PDF 文件夹路径\n",
    "pdf_directory = DOCS_DIR\n",
    "\n",
    "# 获取文件夹中所有 PDF 文件的路径\n",
    "pdf_files = [os.path.join(pdf_directory, f) for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "\n",
    "# 存储所有切分后的文档块\n",
    "all_split_documents = []\n",
    "\n",
    "# 对每个 PDF 文件进行处理\n",
    "for pdf_file in pdf_files:\n",
    "    # 使用 LLMSherpaFileLoader 加载文档\n",
    "    loader = LLMSherpaFileLoader(\n",
    "        file_path=pdf_file,\n",
    "        new_indent_parser=True,\n",
    "        apply_ocr=False,\n",
    "        strategy=\"text\",\n",
    "        llmsherpa_api_url=\"http://0.0.0.0:5001/api/parseDocument?renderFormat=all\"\n",
    "    )\n",
    "    \n",
    "    # 使用 RecursiveCharacterTextSplitter 切分文档\n",
    "    docs_small = loader.load_and_split(\n",
    "        RecursiveCharacterTextSplitter(\n",
    "            chunk_size=100,\n",
    "            chunk_overlap=0,\n",
    "            separators=[\"。\", \"！\", \"？\"],\n",
    "            # separators=[\"。\"],\n",
    "            keep_separator='end',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # docs_big = loader.load_and_split(\n",
    "    #     RecursiveCharacterTextSplitter(\n",
    "    #         chunk_size=200,\n",
    "    #         chunk_overlap=0,\n",
    "    #         separators=[\"。\", \"！\", \"？\"],\n",
    "    #         # separators=[\"。\"],\n",
    "    #         keep_separator='end',\n",
    "    #     )\n",
    "    # )\n",
    "    \n",
    "    # 将切分后的文档块添加到列表中\n",
    "    all_split_documents.extend(docs_small)\n",
    "\n",
    "# # 输出所有切分后的文档块\n",
    "# print(all_split_documents)\n",
    "print(\"清洗之前的chunk数量：\")\n",
    "len(all_split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗之后的chunk数量：\n",
      "6193\n"
     ]
    }
   ],
   "source": [
    "# 切分出来的效果会又些问题，导致重复等，需要我们进行去重操作\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "def get_minhash(doc, num_perm=128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for word in doc.page_content.split():\n",
    "        m.update(word.encode('utf8'))\n",
    "    return m\n",
    "\n",
    "def deduplicate_documents_minhash(documents, threshold=0.8):\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    unique_docs = []\n",
    "    minhashes = []\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        m = get_minhash(doc)\n",
    "        minhashes.append(m)\n",
    "        if not lsh.query(m):\n",
    "            lsh.insert(i, m)\n",
    "            unique_docs.append(doc)\n",
    "\n",
    "    return unique_docs\n",
    "\n",
    "# 对已有document进行去重\n",
    "clean_documents = deduplicate_documents_minhash(all_split_documents)\n",
    "\n",
    "print(\"清洗之后的chunk数量：\")\n",
    "print(len(clean_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################1##################################################\n",
      "中国联通人工智能创新发展论坛在上海成功举办\n",
      "发布时间：2024 年\n",
      "7\n",
      "月 20 日 2024 年\n",
      "7\n",
      "月 19 日，在中国联通合作伙伴大会期间，成功举办了人工智能创新发展论坛。\n",
      "##################################################2##################################################\n",
      " 上海市经信委副主任张宏韬、中国联通总经理简勤、GSMA 中华区总裁斯寒出席论坛并致辞； 中国工程院院士谭建荣，加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩，联 通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波，中国联通人工智能科学 家兼人工智能技术总师廉士国，中国联通数字化部副总经理娄瑜发表主旨演讲。\n",
      "##################################################3##################################################\n",
      "\n",
      "上海市经信委副主任张宏韬在致辞中表示，中国联通作为中央企业，深入贯彻落实国家 “人工智能+”专项行动，在人工智能领域取得了令人瞩目的成就，中国联通人工智能创新中 心充分利用中国联通在网、算、云、数、智、端、业的融合优势，推动了人工智能创新应用 规模化发展，展现了央企在新时代的责任与担当。\n",
      "##################################################4##################################################\n",
      "上海市人民政府也高度重视人工智能的发 展，致力于打造开放的创新平台，吸引全球人工智能企业和人才汇聚，共同推动技术交流和 国际合作。\n",
      "##################################################5##################################################\n",
      "中国联通总经理简勤在致辞中表示，元景 2.0 不仅是中国联通人工智能技术的升级，更 是对人工智能创新发展的展望和承诺，是我们向智能时代更进一步的探索与实践。\n",
      "##################################################6##################################################\n",
      "中国联通 高度重视人工智能产业生态建设，联合产业合作伙伴，共同推动 AI 与产业深度融合，形成 30 多个元景行业大模型，赋能城市治理、工业制造等领域成效明显。\n",
      "##################################################7##################################################\n",
      "未来，将携手各界， 强化技术共研、推动能力共建、促进应用共创、实现合作共赢，以人工智能引领经济社会各 领域从数字化、网络化向智能化跃升。\n",
      "##################################################8##################################################\n",
      "在同日上午举办的合作伙伴大会主峰会上，简勤正式发布了元景大模型 2.0，元景 2.0 展现了文生视频、图像可控生成等多项业界先进的多模态能力。\n",
      "##################################################9##################################################\n",
      "联通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波发表了题为“元景 大模型：更懂行业的模型，产业升级的智能引擎”的主题演讲。\n",
      "##################################################10##################################################\n",
      "推出了元景 2.0 的基座能力、 MaaS 平台、安全能力、行业应用四项能力升级，发布了 2040 亿元景多模态大模型、元景 文生图大模型、元景语音大模型三大基础模型，介绍了已取得中国信息通信研究院评级最高 等级认证的元景 2.0 核心组件 RAG（检索增强生成）和智能体，展示了元景 35+行业大模型、 100+标杆案例的落地成果。\n",
      "##################################################11##################################################\n",
      "朱常波表示，经过长期的技术发展与案例实践，联通元景已获 得客户的普遍认可，获得了“更懂行业的大模型，产业升级的智能引擎”的口碑。\n",
      "中国联通人工智能科学家兼人工智能技术总师廉士国发布了元景标准产品。\n",
      "##################################################12##################################################\n",
      "廉士国介绍 了标准产品的布局，重磅发布了元景 MaaS 平台的八大通用组件，推出了元景热线、元景编 程、元景运维、元景办公四大通用产品，发布了元景大模型一体机。\n",
      "##################################################13##################################################\n",
      "廉士国表示，中国联通 本次发布的创新产品和解决方案，将为各行业的数字化转型及智能化发展提供强有力的支持。 中国联通数字化部副总经理娄瑜发布了中国联通人工智能共享数据集。\n",
      "##################################################14##################################################\n",
      "人工智能共享数 据集是中国联通元景大模型高质高效发展的核心动能，其面向移动通信、政务、新型工业化 等重点行业，拥有大规模、多模态、高质量、强安全的核心优势。\n",
      "##################################################15##################################################\n",
      "娄瑜表示，中国联通愿携 同行业合作伙伴，共同探索共建共享的人工智能数据集生态链。\n",
      "##################################################16##################################################\n",
      " 中国工程院院士谭建荣发表了题为“人工智能大模型的内涵、关键技术与发展趋势”的主 题演讲；加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩发表了题为“构建算 力智联新体系，迈向大模型即服务新时代”的主题演讲。\n",
      "##################################################17##################################################\n",
      " 论坛上，中国联通牵头成立了“人工智能大模型需求与场景应用创新联合体”“人工智能大 模型生态融合创新联合体”两大联合体，启动了“人工智能基础研究共研行动”“人工智能应用 创新基地共建行动”两项行动，提出了“共建高质量人工智能数据集合作倡议”。\n",
      "##################################################18##################################################\n",
      "这一系列关键 举措体现了中国联通积极联合产学研投用各领域打造人工智能融合创新生态的决心。\n",
      "##################################################19##################################################\n",
      "最后，来自各行业的中国联通客户分享了元景大模型的实践案例，包括文创、政务、城 市治理、渔业、装备制造、医疗健康等行业，彰显了中国联通元景大模型赋能千行百业的卓 越能力。\n",
      "##################################################20##################################################\n",
      "在此次合作伙伴大会期间，中国联通还在展区展示了可互动的元景政务、工业、文 创等一系列亮点大模型，吸引了参会嘉宾的目光，取得了良好的展示效果。\n",
      "##################################################21##################################################\n",
      "人工智能是新一轮科技革命和产业变革的重要驱动力量，是推动我国科技跨越发展、产 业优化升级的重要战略资源。\n",
      "##################################################22##################################################\n",
      "未来，中国联通将继续勇担以人工智能推进网络强国、数字中 国建设的重要使命，携手各方行业同仁、合作伙伴共筑人工智能产业新高地，深化务实合作， 共同奋楫笃行新征程，为推动国家人工智能产业创新发展贡献力量。\n",
      "##################################################23##################################################\n",
      "【新征程上的铺路人、赋能者、护航员】系列报道之二十二：砥 砺铸秋实 风劲更远航——记中国联通 2023 年度集团级劳模风 采\n",
      "发布时间：2024-01-10 发布人：新闻宣传中心 2023 年，中国联通涌现出一大批先进模范人物，他们奋斗在不同岗位，有\n",
      "的大胆创新攻坚克难，寻求尖端技术突破，用领先科技赋能数字化建设；有的不 断钻研专业技能，提高自身业务水平，用实际行动守护万家通信……\n",
      "他们来自天南海北，却都闪耀着一样的联通红，积极投身于以数字化网络化\n",
      "智能化助力中国式现代化的伟大实践，在平凡岗位上创造不凡业绩。\n",
      "##################################################24##################################################\n",
      "挑最重的担子 啃最硬的骨头\n",
      "联通华盛电商分公司办公室内的灯火彻夜不熄，这已经成为常态。\n",
      "##################################################25##################################################\n",
      "在这个夏\n",
      "夜的凌晨 12 点钟，APP 渠道负责人张晨正忙碌地在办公室中穿梭，她的步伐坚\n",
      "定有力，神情专注而严肃。为了 618 大促活动的顺利上线，她和团队成员们已经\n",
      "连续多日加班加点，几乎没有休息。\n",
      "##################################################26##################################################\n",
      "张晨一边仔细审核着每一项产品政策，确保其准确无误，一边与供应商保持\n",
      "紧密联系，确认货源情况，以防止任何供应链上的问题可能影响到活动的正常进 行。\n",
      "##################################################27##################################################\n",
      "这种片刻不停歇的繁忙状态并没有让她感到疲惫，反而让她感到安心。“忙 2021 年 7 月，华盛电商应集团要求承接中国联通APP 终端集约化运营项目。\n",
      "##################################################28##################################################\n",
      "这对于张晨和她的团队来说，是一个巨大的挑战也是一次难得的机遇。联通APP 作为日活跃用户超千万的官方线上平台，如何提升用户体验，让其更加便捷、智 能，这是运营者们必须攻克的难题。\n",
      "##################################################29##################################################\n",
      "面对这一重任，张晨并没有退缩。相反，她 迎难而上，展现出了非凡的领导力和决心。她明白，这不仅是一次职业上的考验， 更是一次证明自己能力的机会。\n",
      "##################################################30##################################################\n",
      "“这既是机遇也是挑战，不管多难都要把这块硬 骨头给啃下来！”她在团队会议上坚定地说道。 为了提升终端运营效果，张晨带领团队进行了全面的流程优化。\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"##########\" * 5 + f\"{i+1}\" + \"##########\" * 5)\n",
    "    print(clean_documents[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in clean_documents:\n",
    "    # doc.page_content = doc.page_content.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    # 没有替换\\n，因为有些表格，不应该删除换行\n",
    "    doc.page_content = doc.page_content.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################1##################################################\n",
      "中国联通人工智能创新发展论坛在上海成功举办\n",
      "发布时间：2024年\n",
      "7\n",
      "月20日2024年\n",
      "7\n",
      "月19日，在中国联通合作伙伴大会期间，成功举办了人工智能创新发展论坛。\n",
      "##################################################2##################################################\n",
      "上海市经信委副主任张宏韬、中国联通总经理简勤、GSMA中华区总裁斯寒出席论坛并致辞；中国工程院院士谭建荣，加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩，联通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波，中国联通人工智能科学家兼人工智能技术总师廉士国，中国联通数字化部副总经理娄瑜发表主旨演讲。\n",
      "##################################################3##################################################\n",
      "\n",
      "上海市经信委副主任张宏韬在致辞中表示，中国联通作为中央企业，深入贯彻落实国家“人工智能+”专项行动，在人工智能领域取得了令人瞩目的成就，中国联通人工智能创新中心充分利用中国联通在网、算、云、数、智、端、业的融合优势，推动了人工智能创新应用规模化发展，展现了央企在新时代的责任与担当。\n",
      "##################################################4##################################################\n",
      "上海市人民政府也高度重视人工智能的发展，致力于打造开放的创新平台，吸引全球人工智能企业和人才汇聚，共同推动技术交流和国际合作。\n",
      "##################################################5##################################################\n",
      "中国联通总经理简勤在致辞中表示，元景2.0不仅是中国联通人工智能技术的升级，更是对人工智能创新发展的展望和承诺，是我们向智能时代更进一步的探索与实践。\n",
      "##################################################6##################################################\n",
      "中国联通高度重视人工智能产业生态建设，联合产业合作伙伴，共同推动AI与产业深度融合，形成30多个元景行业大模型，赋能城市治理、工业制造等领域成效明显。\n",
      "##################################################7##################################################\n",
      "未来，将携手各界，强化技术共研、推动能力共建、促进应用共创、实现合作共赢，以人工智能引领经济社会各领域从数字化、网络化向智能化跃升。\n",
      "##################################################8##################################################\n",
      "在同日上午举办的合作伙伴大会主峰会上，简勤正式发布了元景大模型2.0，元景2.0展现了文生视频、图像可控生成等多项业界先进的多模态能力。\n",
      "##################################################9##################################################\n",
      "联通数字科技有限公司总裁、中国联通人工智能创新中心主任朱常波发表了题为“元景大模型：更懂行业的模型，产业升级的智能引擎”的主题演讲。\n",
      "##################################################10##################################################\n",
      "推出了元景2.0的基座能力、MaaS平台、安全能力、行业应用四项能力升级，发布了2040亿元景多模态大模型、元景文生图大模型、元景语音大模型三大基础模型，介绍了已取得中国信息通信研究院评级最高等级认证的元景2.0核心组件RAG（检索增强生成）和智能体，展示了元景35+行业大模型、100+标杆案例的落地成果。\n",
      "##################################################11##################################################\n",
      "朱常波表示，经过长期的技术发展与案例实践，联通元景已获得客户的普遍认可，获得了“更懂行业的大模型，产业升级的智能引擎”的口碑。\n",
      "中国联通人工智能科学家兼人工智能技术总师廉士国发布了元景标准产品。\n",
      "##################################################12##################################################\n",
      "廉士国介绍了标准产品的布局，重磅发布了元景MaaS平台的八大通用组件，推出了元景热线、元景编程、元景运维、元景办公四大通用产品，发布了元景大模型一体机。\n",
      "##################################################13##################################################\n",
      "廉士国表示，中国联通本次发布的创新产品和解决方案，将为各行业的数字化转型及智能化发展提供强有力的支持。中国联通数字化部副总经理娄瑜发布了中国联通人工智能共享数据集。\n",
      "##################################################14##################################################\n",
      "人工智能共享数据集是中国联通元景大模型高质高效发展的核心动能，其面向移动通信、政务、新型工业化等重点行业，拥有大规模、多模态、高质量、强安全的核心优势。\n",
      "##################################################15##################################################\n",
      "娄瑜表示，中国联通愿携同行业合作伙伴，共同探索共建共享的人工智能数据集生态链。\n",
      "##################################################16##################################################\n",
      "中国工程院院士谭建荣发表了题为“人工智能大模型的内涵、关键技术与发展趋势”的主题演讲；加拿大工程院院士、欧洲科学院院士、香港科技大学教授郭嵩发表了题为“构建算力智联新体系，迈向大模型即服务新时代”的主题演讲。\n",
      "##################################################17##################################################\n",
      "论坛上，中国联通牵头成立了“人工智能大模型需求与场景应用创新联合体”“人工智能大模型生态融合创新联合体”两大联合体，启动了“人工智能基础研究共研行动”“人工智能应用创新基地共建行动”两项行动，提出了“共建高质量人工智能数据集合作倡议”。\n",
      "##################################################18##################################################\n",
      "这一系列关键举措体现了中国联通积极联合产学研投用各领域打造人工智能融合创新生态的决心。\n",
      "##################################################19##################################################\n",
      "最后，来自各行业的中国联通客户分享了元景大模型的实践案例，包括文创、政务、城市治理、渔业、装备制造、医疗健康等行业，彰显了中国联通元景大模型赋能千行百业的卓越能力。\n",
      "##################################################20##################################################\n",
      "在此次合作伙伴大会期间，中国联通还在展区展示了可互动的元景政务、工业、文创等一系列亮点大模型，吸引了参会嘉宾的目光，取得了良好的展示效果。\n",
      "##################################################21##################################################\n",
      "人工智能是新一轮科技革命和产业变革的重要驱动力量，是推动我国科技跨越发展、产业优化升级的重要战略资源。\n",
      "##################################################22##################################################\n",
      "未来，中国联通将继续勇担以人工智能推进网络强国、数字中国建设的重要使命，携手各方行业同仁、合作伙伴共筑人工智能产业新高地，深化务实合作，共同奋楫笃行新征程，为推动国家人工智能产业创新发展贡献力量。\n",
      "##################################################23##################################################\n",
      "【新征程上的铺路人、赋能者、护航员】系列报道之二十二：砥砺铸秋实风劲更远航——记中国联通2023年度集团级劳模风采\n",
      "发布时间：2024-01-10发布人：新闻宣传中心2023年，中国联通涌现出一大批先进模范人物，他们奋斗在不同岗位，有\n",
      "的大胆创新攻坚克难，寻求尖端技术突破，用领先科技赋能数字化建设；有的不断钻研专业技能，提高自身业务水平，用实际行动守护万家通信……\n",
      "他们来自天南海北，却都闪耀着一样的联通红，积极投身于以数字化网络化\n",
      "智能化助力中国式现代化的伟大实践，在平凡岗位上创造不凡业绩。\n",
      "##################################################24##################################################\n",
      "挑最重的担子啃最硬的骨头\n",
      "联通华盛电商分公司办公室内的灯火彻夜不熄，这已经成为常态。\n",
      "##################################################25##################################################\n",
      "在这个夏\n",
      "夜的凌晨12点钟，APP渠道负责人张晨正忙碌地在办公室中穿梭，她的步伐坚\n",
      "定有力，神情专注而严肃。为了618大促活动的顺利上线，她和团队成员们已经\n",
      "连续多日加班加点，几乎没有休息。\n",
      "##################################################26##################################################\n",
      "张晨一边仔细审核着每一项产品政策，确保其准确无误，一边与供应商保持\n",
      "紧密联系，确认货源情况，以防止任何供应链上的问题可能影响到活动的正常进行。\n",
      "##################################################27##################################################\n",
      "这种片刻不停歇的繁忙状态并没有让她感到疲惫，反而让她感到安心。“忙2021年7月，华盛电商应集团要求承接中国联通APP终端集约化运营项目。\n",
      "##################################################28##################################################\n",
      "这对于张晨和她的团队来说，是一个巨大的挑战也是一次难得的机遇。联通APP作为日活跃用户超千万的官方线上平台，如何提升用户体验，让其更加便捷、智能，这是运营者们必须攻克的难题。\n",
      "##################################################29##################################################\n",
      "面对这一重任，张晨并没有退缩。相反，她迎难而上，展现出了非凡的领导力和决心。她明白，这不仅是一次职业上的考验，更是一次证明自己能力的机会。\n",
      "##################################################30##################################################\n",
      "“这既是机遇也是挑战，不管多难都要把这块硬骨头给啃下来！”她在团队会议上坚定地说道。为了提升终端运营效果，张晨带领团队进行了全面的流程优化。\n",
      "##################################################31##################################################\n",
      "他们加班加点，反复进行体验测试，逐一对标市场上其他优秀的终端应用，找出差距并加以改进。优化终端购买过程中可能出现的各种问题，是一项复杂且繁琐的工作，但张晨和她的团队始终保持高度的专业性和热情。\n",
      "##################################################32##################################################\n",
      "在她的带领下，团队成员们齐心协力，攻坚克难，实现了联通APP终端销量的规模大幅提升。在这一过程中，张晨不仅是团队的领导者，更是每一位成员的榜样。她的勤奋和坚持，激励着团队成员们共同奋斗。\n",
      "##################################################33##################################################\n",
      "每当夜深人静，办公室内仍然灯火通明，团队成员们埋头苦干的身影，正是对她工作态度的最好诠释。\n",
      "##################################################34##################################################\n",
      "通过他们的不懈努力，联通APP终端集约化运营项目取得了令人瞩目的成绩，用户体验显著提升，市场竞争力大大增强。\n",
      "##################################################35##################################################\n",
      "年，为完成中国国家版本馆信息化协同体系建设项目，联通数科公司郭年作为项目总负责人，承担起了重任。\n",
      "##################################################36##################################################\n",
      "他常年带领团队奔波于北京、广州、杭州和西安，这些城市不仅地理位置各异，而且在项目启动初期交通极为不便。面对这样的挑战，郭年毫不退缩，他经常顶着40多度的酷暑，徒步数公里到达项目现场。\n",
      "##################################################37##################################################\n",
      "在那里，他组织并主持了百余次的方案研讨会，通过与各方专家的密切合作，逐步明确并完善了总分馆协同信息化建设体系。\n",
      "##################################################38##################################################\n",
      "这个体系不仅实现了各版本馆之间的数字版本资源的统一管理和高效协同，还大大提升了资源的利用效率和管理水平。\n",
      "##################################################39##################################################\n",
      "在党的执政能力提升工程——某部委宣传文化政务服务平台项目中，郭年再次展示了其卓越的领导力和专业能力。他深入调研了10多个处室的具体需求，全面了解和分析他们在日常工作中所遇到的各类问题和挑战。\n",
      "##################################################40##################################################\n",
      "为了确保方案的切实可行，他参加了50余场技术研讨会，与各领域的专家和技术人员进行深入交流，最终制定出了一套全栈信创化云平台。\n",
      "##################################################41##################################################\n",
      "这一平台采用了先进的Devops敏捷开发架构，实现了10多类系统的整合和46项政务服务事项的“一网通办、全程网办”。\n",
      "##################################################42##################################################\n",
      "这一成果不仅极大地提高了政务服务的效率和便捷性，还在全国范围内树立了政务信息化建设的新标杆，并因此荣获了鼎新杯一等奖，这无疑是对郭年及其团队辛勤付出的最高褒奖。\n",
      "##################################################43##################################################\n",
      "不仅在政务行业信息化建设方面，郭年还在近年来成功走通了信创化与数字化融合发展之路，提出了联通信创云能力图谱。\n",
      "##################################################44##################################################\n",
      "这一图谱不仅为中宣部宣传云、国家药监云、国家农业农村部遥感云、北京市警务云等重点项目的突破奠定了坚实的基础，更为联通在信创云领域跻身第一梯队打下了坚实的基础。\n",
      "##################################################45##################################################\n",
      "在这些项目中，郭年和他的团队充分展示了他们的创新能力和专业精神，通过不断的技术创新和流程优化，确保了项目的顺利实施和高效运行。网络安全是一场没有硝烟的战争，而张文正是这场战争中的一名无名英雄。\n",
      "##################################################46##################################################\n",
      "每天，他的工作都是从紧张而忙碌的状态中开始。“文哥，刚刚几个业务单元上报的安全事件，涉及多个相同的高危互联网访问行为。”这样的报告几乎每天都会出现在他的桌面上。\n",
      "##################################################47##################################################\n",
      "接收、研判、上报、溯源、处置，张文已经习惯了这种高强度的工作节奏。他和他的同事们每天都要处理上千条的告警信息，这些信息背后可能隐藏着对国家和企业信息安全的巨大威胁。\n",
      "##################################################48##################################################\n",
      "打好每一场保卫战！网络安全是一个没有硝烟的战场，要打好每一场保卫战，做到万无一失，“因为一失就意味着万无”。这是张文常挂在嘴边的一句话。\n",
      "##################################################49##################################################\n",
      "在各类重要活动发布保障任务开始前，他就已经在脑海里一遍又一遍地模拟可能出现的攻击路径，并制定出详细的防御方案和应急处置措施。\n",
      "##################################################50##################################################\n",
      "从他接受任务的那一刻起，他的脑海里就不停地思考着各种可能的情况，确保在任何紧急情况下都能够迅速有效地应对。\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(\"##########\" * 5 + f\"{i+1}\" + \"##########\" * 5)\n",
    "    print(clean_documents[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用MinerU进行文档提取(简直无语了，巨慢，8页纸居然用了2min5s左右)\n",
    "# import os\n",
    "\n",
    "# from loguru import logger\n",
    "\n",
    "# from magic_pdf.data.data_reader_writer import FileBasedDataWriter\n",
    "# from magic_pdf.pipe.UNIPipe import UNIPipe\n",
    "\n",
    "\n",
    "\n",
    "# try:\n",
    "#     # current_script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#     # demo_name = 'demo1'\n",
    "#     # pdf_path = os.path.join(current_script_dir, f'{demo_name}.pdf')\n",
    "\n",
    "#     current_script_dir = \"/root/autodl-tmp/dataset/rag/A_small\"\n",
    "#     demo_name = \"AF01\"\n",
    "#     pdf_path = os.path.join(current_script_dir, f'{demo_name}.pdf')\n",
    "#     pdf_bytes = open(pdf_path, 'rb').read()\n",
    "#     jso_useful_key = {'_pdf_type': '', 'model_list': []}\n",
    "#     local_image_dir = os.path.join(current_script_dir, 'images')\n",
    "#     image_dir = str(os.path.basename(local_image_dir))\n",
    "#     image_writer = FileBasedDataWriter(local_image_dir)\n",
    "#     pipe = UNIPipe(pdf_bytes, jso_useful_key, image_writer)\n",
    "#     # pipe.pipe_classify()\n",
    "#     # pipe.pipe_analyze()\n",
    "#     pipe.pipe_parse()\n",
    "#     md_content = pipe.pipe_mk_markdown(image_dir, drop_mode='none')\n",
    "#     with open(f'{demo_name}.md', 'w', encoding='utf-8') as f:\n",
    "#         f.write(md_content)\n",
    "# except Exception as e:\n",
    "#     logger.exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用llmsherpa\n",
    "# # from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "# # llmsherpa_api_url = \"http://127.0.0.1:5001//api/parseDocument?renderFormat=all\"\n",
    "# # pdf_url = \"/root/autodl-tmp/dataset/rag/A_small/AF01.pdf\" # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
    "# # pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "# # doc = pdf_reader.read_pdf(pdf_url)\n",
    "\n",
    "# from langchain_community.document_loaders.llmsherpa import LLMSherpaFileLoader\n",
    "\n",
    "# loader = LLMSherpaFileLoader(\n",
    "#     file_path=\"/root/autodl-tmp/dataset/rag/A_small/AF01.pdf\",\n",
    "#     new_indent_parser=True,\n",
    "#     apply_ocr=False,\n",
    "#     strategy=\"html\",\n",
    "#     # llmsherpa_api_url=\"http://127.0.0.1:5001/api/parseDocument?renderFormat=all&useNewIndentParser=true&applyOcr=yes\"\n",
    "#     llmsherpa_api_url=\"http://0.0.0.0:5001/api/parseDocument?renderFormat=all\",\n",
    "# )\n",
    "\n",
    "# docs = loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17591/3327796113.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n"
     ]
    }
   ],
   "source": [
    "# 如果index不存在，创建一个index\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
    "\n",
    "api_key = \"pcsk_43QZGm_EEk7V2hAogimUuXn7uW9xVdf8UBaHDaWt5mjCbE5AYAtwxaqhThPFfkK42FpLP\"\n",
    "os.environ['PINECONE_API_KEY'] = api_key\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "import time\n",
    "\n",
    "index_name = \"langchain-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "# index = pc.Index(index_name)\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_existing_index(index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本块向量化（比赛限定使用bge-large-zh-v1.5模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 194/194 [00:24<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# 只有当重新写入的时候才需要运行\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMB_MODEL, show_progress=True)\n",
    "\n",
    "#使用faiss作为数据库\n",
    "vectordb = FAISS.from_documents(   \n",
    "    documents=clean_documents,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "faiss_retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "\n",
    "# # vectordb.save_local(PERSIST_DIR)\n",
    "\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# index_name = \"langchain-index\"  # change if desired\n",
    "\n",
    "# os.environ['PINECONE_API_KEY'] = \"pcsk_43QZGm_EEk7V2hAogimUuXn7uW9xVdf8UBaHDaWt5mjCbE5AYAtwxaqhThPFfkK42FpLP\"\n",
    "\n",
    "# # vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "# # 下面这种生成方式可以更加快速地写入数据，1w4数据，写入只需要2min\n",
    "# vectorstore = PineconeVectorStore.from_documents(clean_documents, index_name=index_name, embedding=embeddings, batch_size=100, pool_threads=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vectorstore.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混合检索器\n",
    "\n",
    "#### bm25 \n",
    "- k1 较高的 k1 值意味着词频对评分的影响更大。\n",
    "- b  当 b=1 时，文档长度的影响最大；当b = 0 时，文档长度不影响评分。\n",
    "- langchain 默认切分英文split()，中文需要jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.719 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "# dense_retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 5, \"score_threshold\": 0.5},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_split_documents, \n",
    "    k=5, \n",
    "    bm25_params={\"k1\": 1.5, \"b\": 0.75}, \n",
    "    preprocess_func=jieba.lcut\n",
    ")\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, dense_retriever], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本召回和重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.retrievers import ContextualCompressionRetriever\n",
    "# from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "# from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# def rerank(questions, retriever, top_n=5, cut_len=384):\n",
    "#     rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)\n",
    "#     compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)\n",
    "#     compression_retriever = ContextualCompressionRetriever(\n",
    "#         base_compressor=compressor, base_retriever=retriever\n",
    "#     )\n",
    "#     rerank_answers = []\n",
    "#     for question in tqdm(questions):\n",
    "#         relevant_docs = compression_retriever.invoke(question)\n",
    "#         answer=''\n",
    "#         for rd in relevant_docs:\n",
    "#             answer += rd.page_content\n",
    "#         rerank_answers.append(answer[:cut_len])\n",
    "#     return rerank_answers\n",
    "\n",
    "# questions = list(query['question'].values)\n",
    "# rerank_answers = rerank(questions, ensemble_retriever)\n",
    "# print(rerank_answers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.45it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.88it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.49it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.62it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.54it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.66it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.17it/s]\n",
      "100it [03:54,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加 速向数字科技领军企业转变，实现了四个维度的转型升级：一是联接规模和联接结构升维，从过去的 连接人为主拓展到连接人机物，大力发展物联网和工业互联网；二是核心功能升维，从以基础连接为 主发展到大联接、大计算、大数据、大应用、大安全五大主责主业；三是服务和赋能水平升维，以 5G、云计算、大数据、人工智能、区块链为代表的新一代信息技术和实体经济的结合，服务数字政府、 数字社会、数字经济的能力不断增强；四是发展理念升维，我们以传统的市场驱动为主转变为市场驱 动和创新驱动相结合的发展模式，尤其是加大了科技创新及人才方面的投入力度，创新发展的动能得 到了空前的释放。\n",
      "\n",
      "我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加速向数字科技领军企业转变，实现了四\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "def get_minhash(doc, num_perm=128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for word in doc.page_content.split():\n",
    "        m.update(word.encode('utf8'))\n",
    "    return m\n",
    "\n",
    "def deduplicate_documents_minhash(documents, threshold=0.8):\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=128)\n",
    "    unique_docs = []\n",
    "    minhashes = []\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        m = get_minhash(doc)\n",
    "        minhashes.append(m)\n",
    "        if not lsh.query(m):\n",
    "            lsh.insert(i, m)\n",
    "            unique_docs.append(doc)\n",
    "\n",
    "    return unique_docs\n",
    "\n",
    "def retrieve_documents(query, retriever):\n",
    "    docs = retriever.invoke(query)\n",
    "    # print(f\"the docs is: {docs}\")\n",
    "    return docs\n",
    "\n",
    "def rerank_documents(query, documents, rerank_model, top_n=5):\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=top_n)\n",
    "    relevant_docs = compressor.compress_documents(documents, query)\n",
    "    return relevant_docs\n",
    "\n",
    "\n",
    "def rerank(questions, sub_questions, questions_fyde, retriever, rerank_model_name, top_n=3, cut_len=384):\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=rerank_model_name)\n",
    "    rerank_answers = []\n",
    "\n",
    "    for question, sub_question, question_fyde in tqdm(zip(questions, sub_questions, questions_fyde)):\n",
    "        # 单次调用召回\n",
    "        docs_quer_origin = retrieve_documents(question, retriever)\n",
    "        \n",
    "        # doc_query_new = []\n",
    "        # for sub in sub_question:\n",
    "        #     doc_query = retrieve_documents(sub, retriever)\n",
    "        # doc_query_new.extend(doc_query)\n",
    "        docs_query_first = retrieve_documents(sub_question[0], retriever)\n",
    "        docs_query_second = retrieve_documents(sub_question[1], retriever)\n",
    "        docs_fyde = retrieve_documents(question_fyde, retriever)\n",
    "\n",
    "        # 合并文档\n",
    "        all_docs = docs_quer_origin + docs_query_first + docs_query_second + docs_fyde\n",
    "\n",
    "        # 去重文档\n",
    "        unique_docs = deduplicate_documents_minhash(all_docs)\n",
    "\n",
    "        # print(unique_docs)\n",
    "\n",
    "        # 重新排序\n",
    "        reranked_docs = rerank_documents(question, unique_docs, rerank_model, top_n)\n",
    "\n",
    "        # 提取内容\n",
    "        answer = '\\n'.join(doc.page_content for doc in reranked_docs)\n",
    "        rerank_answers.append(answer[:cut_len])\n",
    "\n",
    "    return rerank_answers\n",
    "\n",
    "# 使用示例\n",
    "questions = list(query[\"question\"].values)\n",
    "sub_questions = list(query['sub_questions'].values)\n",
    "questions_fyde = list(query[\"question_fyde\"].values)\n",
    "\n",
    "rerank_answers = rerank(questions, sub_questions, questions_fyde, ensemble_retriever, RERANK_MODEL)\n",
    "print(rerank_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "embedding sentences: 100%|██████████| 25/25 [00:00<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_model max_seq_length:  512\n",
      "emb_model embeddings_shape:  1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？</td>\n",
       "      <td>\\n我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加 速...</td>\n",
       "      <td>-0.02802,-0.006622,-0.01736,0.004593,0.01402,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>告诉我2022年联通产业互联网收入的同比增长速度。</td>\n",
       "      <td>公司产业互联网继续按下快进键，2022年收入首破700亿大关，同比增长达到29%，实现规模、...</td>\n",
       "      <td>-0.02975,-0.006638,-0.01276,0.003176,0.0429,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>根据2022年度报告，中国联通的企业定位是什么？</td>\n",
       "      <td>\\n公司基本情况\\n1公司简介3公司主要会计数据和财务指标\\n||公司股票简况\\n|---|...</td>\n",
       "      <td>-0.04153,-0.01656,-0.04892,0.014305,0.03244,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022年联通在“大联接”和“大数据”业务上取得了什么成果？</td>\n",
       "      <td>在数字政府、数字金融、智慧文旅、数据安全等领域，实现省市级标杆项目规模复制。联通大数据业务保...</td>\n",
       "      <td>-0.04303,-0.02644,-0.04166,0.0067,0.0238,0.057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022年上半年，联通在精品网络建设上有什么成果？</td>\n",
       "      <td>公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入 230 亿元，同比提...</td>\n",
       "      <td>-0.01903,-0.0219,-0.04358,-0.01787,0.005768,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_id                                       question  \\\n",
       "0        1  根据年度报告，2022年中国联通在向数字科技领军企业转变的过程中实现了哪些维度的转型升级？   \n",
       "1        2                      告诉我2022年联通产业互联网收入的同比增长速度。   \n",
       "2        3                       根据2022年度报告，中国联通的企业定位是什么？   \n",
       "3        4                 2022年联通在“大联接”和“大数据”业务上取得了什么成果？   \n",
       "4        5                      2022年上半年，联通在精品网络建设上有什么成果？   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\n我们坚定践行网络强国、数字中国、智慧社会战略部署，今天的中国联通，正在从传统运营商加 速...   \n",
       "1  公司产业互联网继续按下快进键，2022年收入首破700亿大关，同比增长达到29%，实现规模、...   \n",
       "2  \\n公司基本情况\\n1公司简介3公司主要会计数据和财务指标\\n||公司股票简况\\n|---|...   \n",
       "3  在数字政府、数字金融、智慧文旅、数据安全等领域，实现省市级标杆项目规模复制。联通大数据业务保...   \n",
       "4   公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入 230 亿元，同比提...   \n",
       "\n",
       "                                           embedding  \n",
       "0  -0.02802,-0.006622,-0.01736,0.004593,0.01402,0...  \n",
       "1  -0.02975,-0.006638,-0.01276,0.003176,0.0429,0....  \n",
       "2  -0.04153,-0.01656,-0.04892,0.014305,0.03244,0....  \n",
       "3  -0.04303,-0.02644,-0.04166,0.0067,0.0238,0.057...  \n",
       "4  -0.01903,-0.0219,-0.04358,-0.01787,0.005768,0....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emb(answers, emb_batch_size = 4):\n",
    "    model = SentenceTransformer(EMB_MODEL, trust_remote_code=True).half()\n",
    "    all_sentence_embeddings = []\n",
    "    for i in tqdm(range(0, len(answers), emb_batch_size), desc=\"embedding sentences\"):\n",
    "        batch_sentences = answers[i:i+emb_batch_size]\n",
    "        sentence_embeddings = model.encode(batch_sentences, normalize_embeddings=True)\n",
    "        all_sentence_embeddings.append(sentence_embeddings)\n",
    "    all_sentence_embeddings = np.concatenate(all_sentence_embeddings, axis=0)\n",
    "    print('emb_model max_seq_length: ', model.max_seq_length)\n",
    "    print('emb_model embeddings_shape: ', all_sentence_embeddings.shape[-1])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return all_sentence_embeddings\n",
    "\n",
    "all_sentence_embeddings = emb(rerank_answers)\n",
    "sub['answer'] = rerank_answers\n",
    "sub['embedding']= [','.join([str(a) for a in all_sentence_embeddings[i]]) for i in range(len(all_sentence_embeddings))]\n",
    "sub.to_csv(SUB_DIR, index=None)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the retrieve cost time: 0.07857894897460938s\n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5])\n",
    "\n",
    "question = \"2022年上半年，联通在精品网络建设上有什么成果？\"\n",
    "# question = \"根据2022年度报告，中国联通的企业定位是什么？\"\n",
    "start = time.time()\n",
    "docs_query_first = retrieve_documents(question, ensemble_retriever)\n",
    "\n",
    "# docs_query_first = retrieve_documents(\"告诉我2022年联通产业互联网收入的同比增长速度。\", bm25_retriever)\n",
    "\n",
    "# docs_query_first = retrieve_documents(\"告诉我2022年联通产业互联网收入的同比增长速度。\", dense_retriever)\n",
    "\n",
    "# docs_query_first = retrieve_documents(\"告诉我2022年联通产业互联网收入的同比增长速度。\", faiss_retriever)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"the retrieve cost time: {end - start}s\")\n",
    "rerank_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL, model_kwargs = {'device': 'cuda'})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content='公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入230亿元，同比提升适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战略投入，上半年的精品网络建设卓有成效，为公司有根生长筑牢发展底座。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY12.pdf'}, page_content='（三）网络建设精准高效建设精品网络，网络竞争力不断提升2019年上半年，公司继续坚持以效益和市场为导向的精准高效建设，优先满足“5G+4G”精品网、创新业务等需求，不断提升网络竞争力。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content=' 公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入 230 亿元，同比提升 适度加大战略投入，基础网络能力大幅提升 中国联通始终坚持网络在企业发展中的基础地位，适度加大战略投入，上半年的精品网络建设卓 有成效，为公司有根生长筑牢发展底座。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content='5G/4G精品网建设方面，已经实现重点乡镇以上场景室外连续覆盖，5G中频规模和覆盖水平与行业相当。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY12.pdf'}, page_content='（三）网络建设 精准高效建设精品网络，网络竞争力不断提升 2019 年上半年，公司继续坚持以效益和市场为导向的精准高效建设，优先满足“5G+4G”精 品网、创新业务等需求，不断提升网络竞争力。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY07.pdf'}, page_content='上半年，公司聚焦地区网络质量和客户感知持续提升，移网和固网宽带实时满意度持续提升，网络时延指标行业最优。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AF19.pdf'}, page_content='“请问谁知道在空中飞着的是什么东西呢？”志愿者们以老师的身份向桂林阳朔杨堤乡凤凰小学的学生们提问。课堂气氛异常热烈，同学们积极举手回答问题，脸上洋溢着好奇与兴奋。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY11.pdf'}, page_content='推进基础设施精准建设，网络质量大幅提升公司聚焦“5G+4G”精品网、创新业务等需求，精准高效推进网络基础设施建设。')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_query_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reranker:\n",
    "    def rerank(self, query, passages, top_k=32768):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "class CrossEncoderReranker(Reranker):\n",
    "    def __init__(self):\n",
    "        self.reranker_model = CrossEncoder(RERANK_MODEL, max_length=512, device=\"cuda\", automodel_args={\"torch_dtype\": torch.float16})\n",
    "        \n",
    "    def rerank(self, query, passages, top_k=5):\n",
    "        score_inputs = [[query, passage.page_content] for passage in passages]\n",
    "        scores = self.reranker_model.predict(score_inputs)\n",
    "        # result = [{'question': passage, 'score': score} for passage, score in zip(passages, scores)]\n",
    "        result = [{'idx': idx, 'question': passage, 'score': score} for idx, (passage, score) in enumerate(zip(passages, scores))]\n",
    "        sorted_result = sorted(result, key=lambda x: x['score'], reverse=True)\n",
    "        return sorted_result[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence_transformers.cross_encoder.CrossEncoder.CrossEncoder object at 0x7f463e8f03d0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'idx': 2,\n",
       "  'question': Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content=' 公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入 230 亿元，同比提升 适度加大战略投入，基础网络能力大幅提升 中国联通始终坚持网络在企业发展中的基础地位，适度加大战略投入，上半年的精品网络建设卓 有成效，为公司有根生长筑牢发展底座。'),\n",
       "  'score': 0.9770508},\n",
       " {'idx': 0,\n",
       "  'question': Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content='公司固网宽带业务延续了去年高速增长的良好态势，上半年实现宽带接入收入230亿元，同比提升适度加大战略投入，基础网络能力大幅提升中国联通始终坚持网络在企业发展中的基础地位，适度加大战略投入，上半年的精品网络建设卓有成效，为公司有根生长筑牢发展底座。'),\n",
       "  'score': 0.9663086},\n",
       " {'idx': 3,\n",
       "  'question': Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY02.pdf'}, page_content='5G/4G精品网建设方面，已经实现重点乡镇以上场景室外连续覆盖，5G中频规模和覆盖水平与行业相当。'),\n",
       "  'score': 0.91796875},\n",
       " {'idx': 5,\n",
       "  'question': Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY07.pdf'}, page_content='上半年，公司聚焦地区网络质量和客户感知持续提升，移网和固网宽带实时满意度持续提升，网络时延指标行业最优。'),\n",
       "  'score': 0.90722656},\n",
       " {'idx': 7,\n",
       "  'question': Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY11.pdf'}, page_content='推进基础设施精准建设，网络质量大幅提升公司聚焦“5G+4G”精品网、创新业务等需求，精准高效推进网络基础设施建设。'),\n",
       "  'score': 0.77441406}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_model = CrossEncoderReranker()\n",
    "\n",
    "rerank_model.rerank(question, docs_query_first, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerank_model.reranker_model.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rerank cost time: 0.6038789749145508s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "reranked_docs = rerank_documents(question, docs_query_first, rerank_model , 5)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"the rerank cost time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY12.pdf'}, page_content='2019年上半年，创新业务成为稳定公司收入的主要驱动力。产业互联网业务收入同比增长43%，达到人民币167亿元，占整体主营业务收入比例提高至13%。'),\n",
       " Document(id='24425f68-1c8d-469d-93bc-3cbe40270591', metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY03.pdf'}, page_content='联通云加速发展，实现收入3人民币268.7亿元，同比提升142.0%；IDC实现收入人民币186.1亿元，同比提升12.9%。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AZ09.pdf'}, page_content='算力作为数字经济核心产业的重要底座支撑，对上游软硬件产业的拉动作用日渐凸显，2022年全国电子信息制造业实现营业收入15.4万亿元，同比增长5.5%。'),\n",
       " Document(id='b18ff517-01a9-4082-887e-fe501a6c166b', metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY01.pdf'}, page_content='物联网实现收入86亿元，同比增长达到42%，非连接收入增长63%，增速大幅领跑行业。大计算积厚成势，“联通云”继续翻倍增长，2022年实现收入361亿元，同比增速达到121%。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY11.pdf'}, page_content='2019年，公司创新业务保持快速发展，产业互联网收入同比增长43%，达到人民币329亿元，占整体主营业务收入比例达到12.4%，成为稳定主营业务收入的重要驱动力。'),\n",
       " Document(id='18ef4b27-3e78-4b44-b936-e1749fc4914f', metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY03.pdf'}, page_content='收入结构不断优化，产业互联网业务实现收入人民币531.5亿元，同比大幅提升29.9%，占主营业务收入比达到22.2%。EBITDA1为人民币765.9亿元，比去年同期上升1.9%。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY04.pdf'}, page_content='收入结构不断优化，产业互联网业务实现收入人民币194.19亿元，同比大幅提升34.8%，占整体主营业务收入的比例达到23.9%。'),\n",
       " Document(id='b4301a9a-df8e-4aa9-9a48-a4de94e428ee', metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY01.pdf'}, page_content='公司产业互联网继续按下快进键，2022年收入首破700亿大关，同比增长达到29%，实现规模、增速双提升。'),\n",
       " Document(metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AY12.pdf'}, page_content='2019 年上半年，创新业务成为稳定公司收入的主要驱动力。产业互联网业务收入同比增长 43%，达到人民币 167 亿元，占整体主营业务收入比例提高至 13%。'),\n",
       " Document(id='dc766ea0-8268-4bf0-8520-cde856ad23a2', metadata={'source': '/root/autodl-tmp/dataset/rag/A_document/AZ05.pdf'}, page_content='截至2023年10月，中国联通已经在全国建立了28家产业互联网公司。')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_query_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## 41 ##################################################\n",
      "郭华对工作的严谨态度和高度的责任心，使得他能够在每一次重大任务面前，从容不迫，\n",
      "确保任务顺利完成。为了保障通信业务的顺利进行，郭华常常放弃个人休息时间，全身心地投入到工作中去。\n",
      "郭华以他的实际行动证明了，只要有责任感、有担当，就能在平凡的岗位上创造出不平凡的业绩，为公司的发展和国家的重要活动提供坚实的保障。郭华的领导风格也为团队注入了强大的凝聚力和战斗力。\n",
      "他常年带领团队奔波于北京、广州、杭州和西安，这些城市不仅地理位置各异，而且在项目启动初期交通极为不便。面对这样的挑战，郭年毫不退缩，他经常顶着40多度的酷暑，徒步数公里到达项目现场。\n",
      "################################################## 42 ##################################################\n",
      "本次论坛以“同行跃新智联未来”为主题，重磅发布“知驭”“知略”“知途”三大车联网创新产品和联通人车家生活全生态平台。\n",
      "大会以“算网筑基拥抱智能共促生态发展”为主题，全面展示了中国联通在智算领域全新升级的技术内核及产品能力，并联合行业生态合作伙伴及行业专家，围绕算网数智、人工智能等前沿科技与热点话题展开讨论与分享。\n",
      "数智县域向新无界——中国联通人工智能赋能全域数字化论坛在沪召开\n",
      "发布时间：2024年\n",
      "7\n",
      "月20日\n",
      "7\n",
      "月19日，2024中国联通合作伙伴大会期间，以“数智县域向新无界”为主题的人工智能赋能全域数字化论坛顺利召开。\n",
      "################################################## 43 ##################################################\n",
      "9间接带动经济总产出和经济增加值的增长率测算方法同上。315亿元。二是带动各行业企业对数字化转型的投资。5G、10项目签约金额达209亿元，同比增长28%。\n",
      "2市场规模为2023年全年数据统计，主要依据企业财报、人员访谈、可信云评估、历史数据等得出。对于市场数据不明确的领域，只发布头部企业整体情况，不做具体排名。\n",
      "2023年白皮书在2022年的基础上，加强了全球和我国算力发展的研究，客观评估我国整体、各省份及各城市现阶段的算力发展水平，进一步给出我国算力二十强市榜单，希望为各地推进算力技术产业、基础设施建设及算力应用发展提供参考。\n",
      "################################################## 44 ##################################################\n",
      "\n",
      "聚焦时空AI发布时空大模型\n",
      "多源数据融合、智能决策预警等特色能力，并面向智慧城市、工业互联网、交通文旅、农林牧渔等多个行业领域，持续赋能，全面助力“时空\n",
      "+AI”技术应用的规模化复制推广，为行业数智化转型提供坚实支撑。\n",
      "中国联通依靠多年在经济领域的业务深耕，利用RAG和AIAgent技术，打造的元景经济大模型，以人机对话互动的方式，为发改、统计、工信等领域从业者提供智慧问数、智能分析、知识问答、预测预警、智能报告等特色功能，致力于成为经济领域工作者身边的“AI经济助手”乃至经济学家。\n",
      "人工智能共享数据集是中国联通元景大模型高质高效发展的核心动能，其面向移动通信、政务、新型工业化等重点行业，拥有大规模、多模态、高质量、强安全的核心优势。\n",
      "################################################## 45 ##################################################\n",
      "此次中国联通推出的“畅游欧洲，激情巴黎”出境漫游随心选活动，为用户提供了灵活多样的流量选择，无论是短途旅行还是长时间的欧洲漫游，都能找到合适的流量套餐。\n",
      "例如，参加活动的用户只需支付低至2.97\n",
      "随心选择，畅享体育激情畅享流量，省心放心安心优质服务，极速联通世界\n",
      "元的费用，即可享受到最长10天的出境漫游流量服务。\n",
      "为满足出境旅行客户，尤其是即将前往巴黎和欧洲观赛的体育迷们，对出境漫游流量服务在高品质、超优惠、按需订购、按需使用等方面的需求，中国联通全新推出“畅游欧洲，激情巴黎”出境漫游随心选活动。\n",
      "################################################## 46 ##################################################\n",
      "展望未来，中国联通将立足“数字技术融合创新排头兵”使命，落实自治区“旅游兴疆”战略，以持续提升游客满意度为中心工作，应用联通5G+智慧旅游大模型场景，不断创新服务模式，提升多样化体验服务能力，将“游新疆”平台真正打造成新疆数字文旅名片，通过智慧文旅手段积极推广新疆文化旅游资源，让更多的人了解新疆、来到新疆、爱上新疆。\n",
      "无论是旅游途中还是返程之后，游客都能随时享受到这些产品的独特魅力，感受到新疆的文化底蕴。自上线以来，“游新疆”平台的服务次数已经超过了3000万次，成为广大游客了解和体验新疆的重要窗口。\n",
      "”新版“游新疆”平台，通过不断优化用户界面和功能布局，为广大游客提供了更加亲民、便捷的旅游服务，尤其是对于老年游客而言，无疑是一次体验上的飞跃。\n",
      "################################################## 47 ##################################################\n",
      "三苏文化大数据库的建设过程展示了如何通过现代科技手段，实现对传统文化的保护、传承和活化，为其他文化项目提供了宝贵的经验和参考。\n",
      "中国联通发挥大数据能力优势和多年在文化旅游领域的成功实践，承建三苏文化大数据库，为三苏文化的系统研究、活化利及人工智能能力，解析三苏文化脉络、建立三苏关联融合体系；为博物馆提供共建共享、互联互通的统一平台，是国家首条文物游径“东坡行旅”的数据基石。\n",
      "三苏文化大数据库的成功上线，是中华文化自信的生动体现，是科技赋能文化传承的成功实践。它不仅让人们更加便捷地了解和研究三苏文化，也为中华优秀传统文化的保护与传承提供了新的路径和方法。\n",
      "################################################## 48 ##################################################\n",
      "中国联通作为2024世界智能产业博览会战略合作伙伴以及重要参展单位，以“百年传承三十向新AI赋能数智未来”为主题，设置AI+智算、AI+新型工业化、AI+数字政府、AI+数字社会、AI+数智生活、AI+智慧酒店等六大展岛，展出30余个展项，全方位展示中国联通引领科技创新、赋能千行百业数字化转型的最新成果。\n",
      "大会以“算网筑基拥抱智能共促生态发展”为主题，全面展示了中国联通在智算领域全新升级的技术内核及产品能力，并联合行业生态合作伙伴及行业专家，围绕算网数智、人工智能等前沿科技与热点话题展开讨论与分享。\n",
      "中国联通大批科技成果亮相2024世界智能产业博览会\n",
      "发布时间：2024-06-24发布人：新闻宣传中心6月20日，2024世界智能产业博览会在天津正式开幕。\n",
      "################################################## 49 ##################################################\n",
      "同时，中国联通官网也进行了改版焕新，实现合作联系、业务办理、联通文创等服务功能的一网通办。会上，陈忠岳发布了中国联通的卡通形象“通通”，寓意中国联通网络四通八达、中国联通合作融通共赢。\n",
      "宣传联通为精准扶贫、提速降费所做贡献彰显央企实力和担当形象。\n",
      "奥运会的通信保障，联通着奥运健儿和热情观众，联通着好客中国与广阔世界，联通着伟大复兴中国梦与现代奥运精神。\n",
      "################################################## 50 ##################################################\n",
      "面对如此严峻的情况，全省网络线上下联动，抽调65名党团员志愿者组成网络保障突击队，调派19台抢修专车、1台应急通信车、1台卫星通信车、10台便携油机以及多台卫星电话等应急物资，赶赴华容；到达灾区指定地点后，保障队伍克服重重困难，连夜奋战10多个小时，完成了堤坝沿线、华容安置点区域所有基站的软件扩容，抢通通信线路、机房恢复供电、开通卫星通信。\n",
      "湖南联通第一时间调派无人机飞过钟洞河与布满淤泥的近500米田地，让光缆迅速跨过东西两岸，完成周边网络抢修，4000余名用户恢复通信。\n",
      "同时，紧急开通一条防汛专线，在决堤周边安排专人24小时现场值守，实时监控网络情况，为当地人员聚集区以及防汛指挥部、消防等部门的救灾工作提供通信保障，并积极参与支援当地组织的抢修救灾工作。\n",
      "################################################## 51 ##################################################\n",
      "章思表示，经济社会智能孪生系统建设三大核心特色：一是服务经济治理效能提升，连接民生愿景与幸福实景。\n",
      "中国联通将继续以创新和服务为驱动，不断开拓进取，在新时代的征程中谱写更加辉煌的篇章。\n",
      "三大核心特色，引领智能孪生系统建设百年传承，三十向新，持续赋能国家发展\n",
      "基于多年在数据和通信领域的积累与实践，中国联通智慧足迹推出的经济社会智能孪生系统，旨在通过技术创新和数据融合，为国家经济治理和社会治理提供强有力的支持。\n",
      "################################################## 52 ##################################################\n",
      "该报告通过对市场上主要厂商的全面分析，旨在为 数字政府领域的决策者和相关利益方提供有价值的市场参考和指导。报告的评估 标准主要分为两个维度：能力和战略。\n",
      "该报告通过对市场上主要厂商的全面分析，旨在为数字政府领域的决策者和相关利益方提供有价值的市场参考和指导。报告的评估标准主要分为两个维度：能力和战略。\n",
      "本次评估过程极为严格，IDC 在调研过程中采用了多种方法，包括 深入的访谈、详尽的问卷调查以及对厂商提供的产品和服务进行实地验证。\n",
      "################################################## 53 ##################################################\n",
      "联通数科、中讯设计院入选国资委“创建世界一流专精特新示范企业”， 智网科技、智慧足迹入选国家级专精特新“小巨人”企业，“5G共建共享 SA建设工程”获得国家优质工程金奖。\n",
      "联通数科、中讯设计院入选国资委“创建世界一流专精特新示范企业”，智网科技、智慧足迹入选国家级专精特新“小巨人”企业，“5G共建共享SA建设工程”获得国家优质工程金奖。\n",
      "目前中国联通分别与腾讯、阿里巴巴、网宿科技、金蝶、网龙、中国银行、奇虎360等企业合资成立了系列企业，包括提供智慧文旅产品服务的云景科技、提供智慧城市产品服务的云粒智慧、提供边缘计算产品服务的云际智慧、提供智慧教育产品服务的云启智慧、提供金融科技产品服务的中联云链、提供数字安全产品服务的云盾等19。\n",
      "################################################## 54 ##################################################\n",
      "最后，来自各行业的中国联通客户分享了元景大模型的实践案例，包括文创、政务、城市治理、渔业、装备制造、医疗健康等行业，彰显了中国联通元景大模型赋能千行百业的卓越能力。\n",
      "中国联通依靠多年在经济领域的业务深耕，利用RAG和AIAgent技术，打造的元景经济大模型，以人机对话互动的方式，为发改、统计、工信等领域从业者提供智慧问数、智能分析、知识问答、预测预警、智能报告等特色功能，致力于成为经济领域工作者身边的“AI经济助手”乃至经济学家。\n",
      "人工智能共享数据集是中国联通元景大模型高质高效发展的核心动能，其面向移动通信、政务、新型工业化等重点行业，拥有大规模、多模态、高质量、强安全的核心优势。\n",
      "################################################## 55 ##################################################\n",
      "2024年\n",
      "7\n",
      "月19日，一场汇聚行业精英与创新力量的盛会——中国联通合作伙伴大会“人工智能创新发展论坛”在上海隆重召开。\n",
      "中国联通人工智能创新发展论坛在上海成功举办\n",
      "发布时间：2024年\n",
      "7\n",
      "月20日2024年\n",
      "7\n",
      "月19日，在中国联通合作伙伴大会期间，成功举办了人工智能创新发展论坛。\n",
      "中国联通将把每年的7月19号作为合作伙伴日，以最真挚的诚意和最务实的行动，与合作伙伴向新同行，共创智能新时代！\n",
      "################################################## 56 ##################################################\n",
      "所以我们把这些策略应用在仿真平台，进行有效性测验。”黄兵明补充说。这样的好处显而易见。不仅可以代替人工去解决大量复杂性的计算工作，还可以基于海量的数据提升通信运营商的网络预防和预测能力。\n",
      "\n",
      "他同时强调，对于现有的网络升级改造不是一蹴而就的，需要结合网络的现状以及未来网络的发展趋势，潜心研究，制定合理的优化方案，最终使得网络朝着未来网络新型体系架2021年，时任紫金山实验室综合试验平台中心主任侯春雨，敏锐地意识到了这一发展趋势和巨大潜力。\n",
      "同年3月，在中国联通举办的CUBE-Net3.0网络创新技术论坛上，紫金山实验室应邀与中国联通及行业百余位专家，共同围绕如何推进通信网络转型升级、构建新一代数字基础设施等话题展开深入研讨，并签署战略合作协议。\n",
      "################################################## 57 ##################################################\n",
      "在江苏南京，中国联通与紫金山实验室联合开展毫米波科技攻关，研发出高国产化率毫米波室内分布式微基站，可以满足面向行业用户和个人的高密热点大带宽场景部署需求。\n",
      "同年3月，在中国联通举办的CUBE-Net3.0网络创新技术论坛上，紫金山实验室应邀与中国联通及行业百余位专家，共同围绕如何推进通信网络转型升级、构建新一代数字基础设施等话题展开深入研讨，并签署战略合作协议。\n",
      "既是合作伙伴、也是“老搭档”的紫金山实验室研究员郑直，是黄兵明多年来科研路的见证者，他也感慨于“老搭档”的这股子韧劲儿：“我们的研究成果基于南京、合肥、济南、青岛、上海、苏州6个骨干节点的流量数据构建流量模型，具备流量预测、SLA（服务等级协议）分析、智能故障定位以及秒级智能化路由调整能力，已初步得到了验证。\n",
      "################################################## 58 ##################################################\n",
      "\n",
      "公司基本情况\n",
      "1公司简介3公司主要会计数据和财务指标\n",
      "||公司股票简况\n",
      "|---|---\n",
      "|股票种类|股票上市交易所|股票简称|股票代码\n",
      "|---|---|---|---\n",
      "|A股|上海证券交易所|中国联通|600050\n",
      "|联系人和联系方式|董事会秘书||证券事务代表\n",
      "|姓名|李玉焯||雷晓旭\n",
      "|办公地址|北京市西城区金融大街21号|北京市西城区金融大街21号|\n",
      "|电话|010-66259179||010-66259179\n",
      "|电子信箱|dongmi@chinaunicom.cn||ir@chinaunicom.cn\n",
      "\n",
      "2报告期公司主要业务简介2022年是党的二十大召开之年，也是中国联通全面实施新战略规划的起跑之年，中国联通坚持以习近平新时代中国特色社会主义思想为指导，认真学习宣传贯彻党的二十大精神，坚决贯彻落实党中央、国务院决策部署，坚持以“数字信息基础设施\n",
      "################################################## 59 ##################################################\n",
      "上个月，中国联通在世界互联网大会乌镇峰会上荣获了“2022年世界互联网领先科技成果”奖，还荣获了2022世界人工智能大会一等奖，这些都见证着中国联通科技创新力量的快速成长！\n",
      "前不久，我们在2022年世界宽带论坛上荣获年度最佳数字家庭运营商，这也是对中国联通深耕数字家庭、服务智慧生活的肯定。三是算网融合发展行动计划提档升级，联通云带动“大计算”迎来高速增长。\n",
      "公司连续三年被国资委授予“科技创新突出贡献企业”荣誉称号，荣获2022年世界互联网领先科技成果奖、2022世界人工智能大会一等奖，这些成绩见证了中国联通科技创新力量的快速成长，也坚定了我们走好科技创新发展道路的决心。\n",
      "################################################## 60 ##################################################\n",
      "通过完善公司治理结构、优化内部管理流程、加强风险防控等措施，不断提升企业的治理能力和管理水平。\n",
      "三、深化改革创新，激发企业内生动力中国联通深知，改革是企业发展的不竭动力。\n",
      "各地党委、政府把抓好国企改革三年行动作为重大政治任务，加强组织领导，各地国企改革领导小组积极推动各有关部门协同作战，形成强大合力；国有企业公司制改革基本完成，剥离企业办社会职能和解决历史遗留问题全面扫尾，完善中国特色现代企业制度、健全市场化经营机制等改革重点领域取得实质性突破，重点领域关键环节改革成果丰硕；以改革促发展，国有资本布局结构进一步优化，国资国企服务保障国家重大战略更加有力，支撑地方经济社会和国家重大战略发展作用显著，广大职工热情拥护积极参与改革，社会反响良好，国资国企打赢三年行动收官战的信心决心更加坚定。\n",
      "扎实推进国企改革三年行动，要把深入学习贯彻习近平总书记关于国有企业改革发\n"
     ]
    }
   ],
   "source": [
    "for i in range(40,60):\n",
    "    print(\"##########\"* 5, f\"{i+1}\", \"##########\" * 5)\n",
    "    print(rerank_answers[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query[\"sub_questions\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "hyde_chain = RunnablePassthrough.assign(hypothetical_document=qa_no_context)\n",
    "\n",
    "hyde_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"how to use multi-modal models in a chain and turn chain into a rest api\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后续可能提分点\n",
    "- 引入LLM\n",
    "   * LLM 递归判断/抽取\n",
    "   * rag-fusion 查询改写\n",
    "   * 构建知识图谱\n",
    "\n",
    "\n",
    "\n",
    "### 注意：\n",
    "- 在分块、重排等过程中可以使用公开库和模型，但禁止使用LLM直接生成最终答案。\n",
    "- 禁止使用LLM继续调整精排得到的文本块，如压缩文本块长度；\n",
    "- 禁止使用LLM直接从文档获取问题答案。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
